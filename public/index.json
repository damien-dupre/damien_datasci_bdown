[{"authors":null,"categories":[],"content":"Like every good movies, my previous blog post “Time series clustering with Dynamic Time Warping” deserves a sequel. In this Part 2, I will have a look at the athletes’ training plan for a marathon. Because marathons are such a demanding performance, most of athletes have a specific training plan to follow in order to be prepared. Many different training plan can be found on the web such as this one from the website www.runireland.com.\nIn this blog post I will try to cluster different simulated athlete training plans with Dynamic Time Warping and some seasonality, states and power band extractions.\nList of packages needed\r# data wrangling\rlibrary(dplyr) # data wrangling\rlibrary(tidyr) # datawrangling\r# analysis\rlibrary(dtwclust) # dynamic time warpping\rlibrary(depmixS4) # Hidden Markov Model\rlibrary(WaveletComp) # Wavelet Analysis\r# graphics\rlibrary(ggplot2) # grammar of graphics\rlibrary(ggdendro) # grammar of dendrograms\rlibrary(gtable) # plot organisation\rlibrary(grid) # plot organisation\rlibrary(gridExtra) # plot organisation\r\rData simulation\rFor this purpose, I will create a data frame of 20 athlete training plans with 10 of them with a random plan and 10 with a repeated pattern non synchronized on their date and intensity. The main variable is the distance they have ran of every day since 25 weeks (175 days) before the marathon.\ndate_marathon \u0026lt;- as.Date(\u0026quot;2015-10-26\u0026quot;)\r#\rdf \u0026lt;- NULL\r# random training plan with runs from 5 to 40km with a high proability of non run days (between 25% and 75% depending on athletes)\rfor (i in 1:10){\rrandom_proba \u0026lt;- runif(8)\rrandom_proba \u0026lt;- random_proba/sum(random_proba)\rvalue \u0026lt;- base::sample(\rx = seq(from = 0, to = 40, by = 5), size = 175, replace = TRUE, prob = c(runif(1, 0.25, 0.75),random_proba)\r)\rathlete \u0026lt;- paste0(\u0026quot;athlete_rand_\u0026quot;,i)\rnew_df \u0026lt;- data.frame(athlete = athlete, value = value, rundate = seq.Date(date_marathon-175, date_marathon-1, by=\u0026quot;day\u0026quot;))\rdf \u0026lt;- rbind(df,new_df)\r}\r# training plan with a reapeated pattern with can change according the weeks and with a different intensity according athletes\rfor (i in 11:20){\rvalue \u0026lt;- rep_len(\rx = c(rep(x = 0, sample(1:3, 1)),10,0,15,20,30)*runif(1, 0.5, 1.5),\rlength.out = 175\r)\rathlete \u0026lt;- paste0(\u0026quot;athlete_plan_\u0026quot;,i)\rnew_df \u0026lt;- data.frame(athlete = athlete, value = value, rundate = seq.Date(date_marathon-175, date_marathon-1, by=\u0026quot;day\u0026quot;))\rdf \u0026lt;- rbind(df,new_df)\r}\rOnce we have the data generated, a key trick will be to convert this data frame into a list of time series. The reason behind this choice is the possibility to implement a multivariate DTW analysis in the future (maybe in a Part 3).\nplan_list \u0026lt;- df %\u0026gt;% tidyr::spread(athlete,value) %\u0026gt;%\rdplyr::select(-rundate) %\u0026gt;%\rpurrr::map(~(.))\r\rDTW cluster on raw data\rAfter creating the list of data, let’s implement a simple DTW clustering on the raw data to see if we can identify our two groups.\nDTW model\rNclust \u0026lt;- 2\rdtw_model \u0026lt;- dtwclust::tsclust(series = plan_list, type = \u0026quot;h\u0026quot;, k = Nclust, distance = \u0026quot;dtw_basic\u0026quot;, control = hierarchical_control(method = \u0026quot;complete\u0026quot;),\rpreproc = NULL, #args = tsclust_args(dist = list(window.size = 5L)),\rtrace = TRUE)\r#\rdtw_data \u0026lt;- ggdendro::dendro_data(dtw_model, type=\u0026quot;rectangle\u0026quot;)\r#\rlabels_order \u0026lt;- dtw_data$labels$label\r#\rdtw_result \u0026lt;- data.frame(label = names(plan_list), cluster = factor(stats::cutree(dtw_model, k = Nclust)))\r#\rdtw_data[[\u0026quot;labels\u0026quot;]] \u0026lt;- merge(dtw_data[[\u0026quot;labels\u0026quot;]], dtw_result, by=\u0026quot;label\u0026quot;)\rdtw_result \u0026lt;- dplyr::full_join(dtw_result,dtw_data$labels, by=c(\u0026quot;label\u0026quot;, \u0026quot;cluster\u0026quot;))%\u0026gt;%\rdplyr::arrange(x)\r\rDTW plot\rcluster_box \u0026lt;- aggregate(x~cluster, ggdendro::label(dtw_data), range)\rcluster_box \u0026lt;- data.frame(cluster_box$cluster,cluster_box$x)\rcluster_threshold \u0026lt;- mean(dtw_model$height[length(dtw_model$height)-((Nclust-2):(Nclust-1))])\r#\rnumColors \u0026lt;- length(levels(dtw_result$cluster)) # How many colors you need\rgetColors \u0026lt;- scales::hue_pal() # Create a function that takes a number and returns a qualitative palette of that length (from the scales package)\rmyPalette \u0026lt;- getColors(numColors)\rnames(myPalette) \u0026lt;- levels(dtw_result$cluster) # Give every color an appropriate name\rp1 \u0026lt;- ggplot() + geom_rect(data=cluster_box, aes(xmin=X1-.3, xmax=X2+.3, ymin=0, ymax=cluster_threshold, color=cluster_box.cluster), fill=NA)+\rgeom_segment(data=ggdendro::segment(dtw_data), aes(x=x, y=y, xend=xend, yend=yend)) + coord_flip() + scale_y_continuous(\u0026quot;Distance\u0026quot;) + scale_x_continuous(\u0026quot;\u0026quot;,breaks = 1:20, labels = labels_order) + guides(color=FALSE, fill = FALSE)+\rtheme(\rpanel.grid.major = element_blank(), panel.grid.minor = element_blank(), # remove grids\rpanel.background = element_blank(), axis.text.y = element_text(colour = myPalette[dtw_result$cluster],hjust=0.5),\raxis.ticks.y=element_blank()\r)\r#\rp2 \u0026lt;- as.data.frame(matrix(unlist(plan_list), nrow=length(unlist(plan_list[1])), dimnames = list(c(),names(plan_list)))) %\u0026gt;%\rdplyr::mutate(rundatelocal = seq.Date(date_marathon-175, date_marathon-1, by=\u0026quot;day\u0026quot;)) %\u0026gt;%\rtidyr::gather(key = label,value = value, -rundatelocal) %\u0026gt;%\rdplyr::mutate(label = as.factor(label)) %\u0026gt;%\rdplyr::full_join(., dtw_result, by = \u0026quot;label\u0026quot;) %\u0026gt;% mutate(label = factor(label, levels = rev(as.character(labels_order)))) %\u0026gt;%\rggplot(aes(x = rundatelocal, y = value, colour = as.factor(cluster))) +\rgeom_line() +\rgeom_area(aes(fill = as.factor(cluster))) +\rcoord_cartesian(ylim = c(0,50)) +\rscale_y_continuous(name = \u0026quot;Total distance per day [km]\u0026quot;, breaks = seq(0, 50, by = 50)) +\rscale_x_date(name = \u0026quot;Run Date\u0026quot;, date_breaks = \u0026quot;4 week\u0026quot;, date_labels = \u0026quot;%b %d\u0026quot;) +\rfacet_wrap(~label, ncol = 1, strip.position=\u0026quot;left\u0026quot;) + guides(color=FALSE, fill = FALSE) +\rtheme_bw() + theme(strip.background = element_blank(), strip.text = element_blank())\r#\rplt_list \u0026lt;- list(p2, p1)\rplt_layout \u0026lt;- rbind(c(NA, 2),\rc(1, 2),\rc(NA, 2))\r#\rgrid.arrange(grobs = plt_list, layout_matrix = plt_layout, heights = c(0.04, 1, 0.05))\rI think I get a nice plot thanks to the solutions provided on Stack Overflow graphically speaking (except some overlap with the labels but I’m working on it). The results are not too bad but some of the random plan can be included in the repeated pattern plan. Well randomness can be expected and can create some nice patterns sometimes. Another interesting result is the necessity to increase the cluster number in order to have a clean clustering.\n\rCentroids\rWe can also have a look at the centroids to see with plans are the most representative of the clusters. Obviously with only two clusters, it is not very useful but it can be a key element to distinguish between many different training plans.\ndtw_model_centroids \u0026lt;- data.frame(dtw_model@centroids, rundatelocal = seq.Date(date_marathon-175, date_marathon-1, by=\u0026quot;day\u0026quot;)) %\u0026gt;%\rtidyr::gather(label, totaldistancekm, starts_with(\u0026quot;athlete\u0026quot;)) %\u0026gt;%\rdplyr::left_join(., dtw_result, by = \u0026quot;label\u0026quot;) %\u0026gt;% dplyr::mutate(label = factor(label, levels = rev(labels_order)))\r#\rdtw_model_centroids %\u0026gt;%\rggplot(aes(rundatelocal,totaldistancekm, color = cluster, fill = cluster)) +\rgeom_line() +\rgeom_area() +\rfacet_wrap(~ label + cluster, ncol = 1, strip.position=\u0026quot;right\u0026quot;, labeller=labeller(.rows = label_both)) +\rscale_y_continuous(name = \u0026quot;Total distance per day [km]\u0026quot;) +\rscale_x_date(name = \u0026quot;Run Date\u0026quot;, date_breaks = \u0026quot;4 week\u0026quot;, date_labels = \u0026quot;%b %d\u0026quot;) +\rguides(color=FALSE, fill = FALSE) +\rtheme_bw()\rThe main problem with raw data is the noise. In order to extract recurrent patterns, the randomness of the noise can sometimes simulate non meaningful pattern and then change the cluster structure. Because we are interested in classification of recurrent pattern, a nice thing would be to remove the noise. Noise removal analyses are probably the most important contribution of signal treatment research and many can be applied here such as seasonality decomposition, Hidden Markov Models and power spectrum analysis.\n\rDTW cluster with seasonality decomposition\rR for time series analysis have some unavoidable packages and functions. If you are interested in time series analysis, you probably cannot work without zoo::zoo(), xts::xts() or tibbletime::as_tbl_time(). However for time series analysis, the stats package have one of the most used and nice function: stl(). Stl allows a Seasonal Decomposition of Time Series by Loess which is powerful in order to extract time series noise, trend and seasonality (i.e periods). In our case we will try to use stl() in order to extract training plan seasonality over one week and then to cluster the results with the DTW method.\nSo first let’s apply the stl() decomposition to every time series in our master list.\nextract_seasonality \u0026lt;- function(x, robust){\rx_ts = ts(as.numeric(unlist(x)), frequency = 7)\rstl_test = stl(x_ts, s.window = 7, robust)\rreturn(stl_test$time.series[,1])\r}\r#\rplan_seasonality \u0026lt;- plan_list %\u0026gt;%\rpurrr::map(~extract_seasonality(., robust = TRUE))\rand then let’s process our model and to plot the results.\nNclust \u0026lt;- 2\rdtw_model \u0026lt;- dtwclust::tsclust(series = plan_seasonality, type = \u0026quot;h\u0026quot;, k = Nclust, distance = \u0026quot;dtw_basic\u0026quot;, control = hierarchical_control(method = \u0026quot;complete\u0026quot;),\rpreproc = NULL, #args = tsclust_args(dist = list(window.size = 5L)),\rtrace = TRUE)\r#\rdtw_data \u0026lt;- ggdendro::dendro_data(dtw_model, type=\u0026quot;rectangle\u0026quot;)\r#\rlabels_order \u0026lt;- dtw_data$labels$label\r#\rdtw_result \u0026lt;- data.frame(label = names(plan_seasonality), cluster = factor(stats::cutree(dtw_model, k = Nclust)))\r#\rdtw_data[[\u0026quot;labels\u0026quot;]] \u0026lt;- merge(dtw_data[[\u0026quot;labels\u0026quot;]], dtw_result, by=\u0026quot;label\u0026quot;)\rdtw_result \u0026lt;- dplyr::full_join(dtw_result,dtw_data$labels, by=c(\u0026quot;label\u0026quot;, \u0026quot;cluster\u0026quot;))%\u0026gt;%\rdplyr::arrange(x)\rcluster_box \u0026lt;- aggregate(x~cluster, ggdendro::label(dtw_data), range)\rcluster_box \u0026lt;- data.frame(cluster_box$cluster,cluster_box$x)\rcluster_threshold \u0026lt;- mean(dtw_model$height[length(dtw_model$height)-((Nclust-2):(Nclust-1))])\r#\rnumColors \u0026lt;- length(levels(dtw_result$cluster)) # How many colors you need\rgetColors \u0026lt;- scales::hue_pal() # Create a function that takes a number and returns a qualitative palette of that length (from the scales package)\rmyPalette \u0026lt;- getColors(numColors)\rnames(myPalette) \u0026lt;- levels(dtw_result$cluster) # Give every color an appropriate name\rp1 \u0026lt;- ggplot() + geom_rect(data=cluster_box, aes(xmin=X1-.3, xmax=X2+.3, ymin=0, ymax=cluster_threshold, color=cluster_box.cluster), fill=NA)+\rgeom_segment(data=ggdendro::segment(dtw_data), aes(x=x, y=y, xend=xend, yend=yend)) + coord_flip() + scale_y_continuous(\u0026quot;Distance\u0026quot;) + scale_x_continuous(\u0026quot;\u0026quot;,breaks = 1:20, labels = labels_order) + guides(color=FALSE, fill = FALSE)+\rtheme(\rpanel.grid.major = element_blank(), panel.grid.minor = element_blank(), # remove grids\rpanel.background = element_blank(), axis.text.y = element_text(colour = myPalette[dtw_result$cluster],hjust=0.5),\raxis.ticks.y=element_blank()\r)\r#\rp2 \u0026lt;- as.data.frame(matrix(unlist(plan_seasonality), nrow=length(unlist(plan_seasonality[1])), dimnames = list(c(),names(plan_seasonality)))) %\u0026gt;%\rdplyr::mutate(rundatelocal = seq.Date(date_marathon-175, date_marathon-1, by=\u0026quot;day\u0026quot;)) %\u0026gt;%\rtidyr::gather(key = label,value = value, -rundatelocal) %\u0026gt;%\rdplyr::mutate(label = as.factor(label)) %\u0026gt;%\rdplyr::full_join(., dtw_result, by = \u0026quot;label\u0026quot;) %\u0026gt;% mutate(label = factor(label, levels = rev(as.character(labels_order)))) %\u0026gt;%\rggplot(aes(x = rundatelocal, y = value, colour = as.factor(cluster))) +\rgeom_line() +\rgeom_area(aes(fill = as.factor(cluster))) +\rcoord_cartesian(ylim = c(-25,25)) +\rscale_y_continuous(name = \u0026quot;Seasonal distance per day [km]\u0026quot;, breaks = seq(-25, 25, by = 50)) +\rscale_x_date(name = \u0026quot;Run Date\u0026quot;, date_breaks = \u0026quot;4 week\u0026quot;, date_labels = \u0026quot;%b %d\u0026quot;) +\rfacet_wrap(~label, ncol = 1, strip.position=\u0026quot;left\u0026quot;) + guides(color=FALSE, fill = FALSE) +\rtheme_bw() + theme(strip.background = element_blank(), strip.text = element_blank())\r#\rplt_list \u0026lt;- list(p2, p1)\rplt_layout \u0026lt;- rbind(c(NA, 2),\rc(1, 2),\rc(NA, 2))\r#\rgrid.arrange(grobs = plt_list, layout_matrix = plt_layout, heights = c(0.04, 1, 0.05))\rWell that’s an epic fail I think but let’s have a look why. Different reasons can explain why we have a first cluster with only 3 time series and as second with all the 17 remaining ones:\nI am using only 2 clusters. In the real life (and in real randomness) a large amount of pattern is possible thus increasing the number of clusters can make the clustering more efficient (if an evaluation of the best fit with cluster number is performed).\rBy removing the noise in the random plan, I made them not random at all and we can see now the repetition of the patterns. This is exactly what I want in my research with real data but here it made a mess.\r\rSo let’s try another method!\n\rDTW cluster with Hidden Markov Model\rI’m not a perfect expert in Hidden Markov Model (HMM) and after having a look at the book Hidden Markov Models for Time Series An Introduction Using R by Walter Zucchini, Iain L. MacDonald and Roland Langrock, I can surely say that it is a complicated question. However in a nutshell HMM are clustering the values according their probability to be part of a “state”. In our case, let’s say that we have three states possible per day “no run”, “medium run” and “long run”. By using HMM it is possible to create new time series based on states instead on distance. It’s a qualitative transformation without any prior assumption about the states boundaries (almost).\nplan_HMM \u0026lt;- as.data.frame(matrix(unlist(plan_list), nrow=length(unlist(plan_list[1])), dimnames = list(c(),names(plan_list)))) %\u0026gt;%\rdplyr::mutate(rundatelocal = seq.Date(date_marathon-175, date_marathon-1, by=\u0026quot;day\u0026quot;)) %\u0026gt;%\rtidyr::gather(key = label,value = value, -rundatelocal) %\u0026gt;%\rdplyr::mutate(label = as.factor(label)) %\u0026gt;%\rdplyr::mutate(value = as.integer(value))\r#\rmod \u0026lt;- depmixS4::depmix(value~label, family = poisson(link = \u0026quot;log\u0026quot;), nstates = 3, data = plan_HMM)\r#\rfm \u0026lt;- depmixS4::fit(mod, verbose = FALSE)\r#\rprobs \u0026lt;- depmixS4::posterior(fm)\r#\rplan_HMM \u0026lt;- cbind(plan_HMM,probs) %\u0026gt;%\rdplyr::select(rundatelocal,label,state) %\u0026gt;%\rtidyr::spread(label,state) %\u0026gt;%\rdplyr::select(-rundatelocal) %\u0026gt;%\rpurrr::map(~(.))\rNclust \u0026lt;- 2\rdtw_model \u0026lt;- dtwclust::tsclust(series = plan_HMM, type = \u0026quot;h\u0026quot;, k = Nclust, distance = \u0026quot;dtw_basic\u0026quot;, control = hierarchical_control(method = \u0026quot;complete\u0026quot;),\rpreproc = NULL, #args = tsclust_args(dist = list(window.size = 5L)),\rtrace = TRUE)\r#\rdtw_data \u0026lt;- ggdendro::dendro_data(dtw_model, type=\u0026quot;rectangle\u0026quot;)\r#\rlabels_order \u0026lt;- dtw_data$labels$label\r#\rdtw_result \u0026lt;- data.frame(label = names(plan_HMM), cluster = factor(stats::cutree(dtw_model, k = Nclust)))\r#\rdtw_data[[\u0026quot;labels\u0026quot;]] \u0026lt;- merge(dtw_data[[\u0026quot;labels\u0026quot;]], dtw_result, by=\u0026quot;label\u0026quot;)\rdtw_result \u0026lt;- dplyr::full_join(dtw_result,dtw_data$labels, by=c(\u0026quot;label\u0026quot;, \u0026quot;cluster\u0026quot;))%\u0026gt;%\rdplyr::arrange(x)\rcluster_box \u0026lt;- aggregate(x~cluster, ggdendro::label(dtw_data), range)\rcluster_box \u0026lt;- data.frame(cluster_box$cluster,cluster_box$x)\rcluster_threshold \u0026lt;- mean(dtw_model$height[length(dtw_model$height)-((Nclust-2):(Nclust-1))])\r#\rnumColors \u0026lt;- length(levels(dtw_result$cluster)) # How many colors you need\rgetColors \u0026lt;- scales::hue_pal() # Create a function that takes a number and returns a qualitative palette of that length (from the scales package)\rmyPalette \u0026lt;- getColors(numColors)\rnames(myPalette) \u0026lt;- levels(dtw_result$cluster) # Give every color an appropriate name\rp1 \u0026lt;- ggplot() + geom_rect(data=cluster_box, aes(xmin=X1-.3, xmax=X2+.3, ymin=0, ymax=cluster_threshold, color=cluster_box.cluster), fill=NA)+\rgeom_segment(data=ggdendro::segment(dtw_data), aes(x=x, y=y, xend=xend, yend=yend)) + coord_flip() + scale_y_continuous(\u0026quot;Distance\u0026quot;) + scale_x_continuous(\u0026quot;\u0026quot;,breaks = 1:20, labels = labels_order) + guides(color=FALSE, fill = FALSE)+\rtheme(\rpanel.grid.major = element_blank(), panel.grid.minor = element_blank(), # remove grids\rpanel.background = element_blank(), axis.text.y = element_text(colour = myPalette[dtw_result$cluster],hjust=0.5),\raxis.ticks.y=element_blank()\r)\r#\rp2 \u0026lt;- as.data.frame(matrix(unlist(plan_HMM), nrow=length(unlist(plan_HMM[1])), dimnames = list(c(),names(plan_HMM)))) %\u0026gt;%\rdplyr::mutate(rundatelocal = seq.Date(date_marathon-175, date_marathon-1, by=\u0026quot;day\u0026quot;)) %\u0026gt;%\rtidyr::gather(key = label,value = value, -rundatelocal) %\u0026gt;%\rdplyr::mutate(label = as.factor(label)) %\u0026gt;%\rdplyr::full_join(., dtw_result, by = \u0026quot;label\u0026quot;) %\u0026gt;% mutate(label = factor(label, levels = rev(as.character(labels_order)))) %\u0026gt;%\rggplot(aes(x = rundatelocal, y = value, colour = as.factor(cluster))) +\rgeom_line() +\rgeom_area(aes(fill = as.factor(cluster))) +\rcoord_cartesian(ylim = c(0,4)) +\rscale_y_continuous(name = \u0026quot;States per day [km]\u0026quot;, breaks = seq(0, 4, by = 4)) +\rscale_x_date(name = \u0026quot;Run Date\u0026quot;, date_breaks = \u0026quot;4 week\u0026quot;, date_labels = \u0026quot;%b %d\u0026quot;) +\rfacet_wrap(~label, ncol = 1, strip.position=\u0026quot;left\u0026quot;) + guides(color=FALSE, fill = FALSE) +\rtheme_bw() + theme(strip.background = element_blank(), strip.text = element_blank())\r#\rplt_list \u0026lt;- list(p2, p1)\rplt_layout \u0026lt;- rbind(c(NA, 2),\rc(1, 2),\rc(NA, 2))\r#\rgrid.arrange(grobs = plt_list, layout_matrix = plt_layout, heights = c(0.04, 1, 0.05))\rGood news this time, the clusters are almost equally distributed, bad news random plans and pattern plans are mixed together. However we can see that the HMM is creating surprisingly nice pattern which can be easily clustered with a higher number of cluster. The drawback is the low distance between each time series which can make the clustering method more complicated.\n\rDTW cluster by power spectral density\rLast but not least, the probable best approach to evaluate seasonality/frequency in training plan pattern can be the power spectrum analysis. By identifying the underlying frequencies of each time series it is possible to cluster them according their pattern. A nice new package WaveletComp can be used for this purpose. WaveletComp is analyzing the frequency structure of uni- and bivariate time series using the Morlet wavelet.\nextract_poweravg \u0026lt;- function(x){\rx \u0026lt;- as.data.frame(x)\rpower_spectrum \u0026lt;- WaveletComp::analyze.wavelet(\rmy.data = x,\rmy.series = 1,\rloess.span = 0,\rdt = 1,\rverbose = FALSE\r)\rmax_period \u0026lt;- max(power_spectrum$Period)\rdat \u0026lt;- spline(power_spectrum$Power.avg, n = max_period)$y # WARNING:power band starts at 2 not 1\rreturn(dat)\r}\rplan_poweravge \u0026lt;- plan_list %\u0026gt;%\rpurrr::map(~extract_poweravg(.))\rNclust \u0026lt;- 2\rdtw_model \u0026lt;- dtwclust::tsclust(series = plan_poweravge, type = \u0026quot;h\u0026quot;, k = Nclust, distance = \u0026quot;dtw_basic\u0026quot;, control = hierarchical_control(method = \u0026quot;complete\u0026quot;),\rpreproc = NULL, #args = tsclust_args(dist = list(window.size = 5L)),\rtrace = TRUE)\r#\rdtw_data \u0026lt;- ggdendro::dendro_data(dtw_model, type=\u0026quot;rectangle\u0026quot;)\r#\rlabels_order \u0026lt;- dtw_data$labels$label\r#\rdtw_result \u0026lt;- data.frame(label = names(plan_poweravge), cluster = factor(stats::cutree(dtw_model, k = Nclust)))\r#\rdtw_data[[\u0026quot;labels\u0026quot;]] \u0026lt;- merge(dtw_data[[\u0026quot;labels\u0026quot;]], dtw_result, by=\u0026quot;label\u0026quot;)\rdtw_result \u0026lt;- dplyr::full_join(dtw_result,dtw_data$labels, by=c(\u0026quot;label\u0026quot;, \u0026quot;cluster\u0026quot;))%\u0026gt;%\rdplyr::arrange(x)\rcluster_box \u0026lt;- aggregate(x~cluster, ggdendro::label(dtw_data), range)\rcluster_box \u0026lt;- data.frame(cluster_box$cluster,cluster_box$x)\rcluster_threshold \u0026lt;- mean(dtw_model$height[length(dtw_model$height)-((Nclust-2):(Nclust-1))])\r#\rnumColors \u0026lt;- length(levels(dtw_result$cluster)) # How many colors you need\rgetColors \u0026lt;- scales::hue_pal() # Create a function that takes a number and returns a qualitative palette of that length (from the scales package)\rmyPalette \u0026lt;- getColors(numColors)\rnames(myPalette) \u0026lt;- levels(dtw_result$cluster) # Give every color an appropriate name\rp1 \u0026lt;- ggplot() + geom_rect(data=cluster_box, aes(xmin=X1-.3, xmax=X2+.3, ymin=0, ymax=cluster_threshold, color=cluster_box.cluster), fill=NA)+\rgeom_segment(data=ggdendro::segment(dtw_data), aes(x=x, y=y, xend=xend, yend=yend)) + coord_flip() + scale_y_continuous(\u0026quot;Distance\u0026quot;) + scale_x_continuous(\u0026quot;\u0026quot;,breaks = 1:20, labels = labels_order) + guides(color=FALSE, fill = FALSE)+\rtheme(\rpanel.grid.major = element_blank(), panel.grid.minor = element_blank(), # remove grids\rpanel.background = element_blank(), axis.text.y = element_text(colour = myPalette[dtw_result$cluster],hjust=0.5),\raxis.ticks.y=element_blank()\r)\r#\rp2 \u0026lt;- as.data.frame(matrix(unlist(plan_poweravge), nrow=length(unlist(plan_poweravge[1])), dimnames = list(c(),names(plan_poweravge)))) %\u0026gt;%\rdplyr::mutate(rundatelocal = 1:n()) %\u0026gt;%\rtidyr::gather(key = label,value = value, -rundatelocal) %\u0026gt;%\rdplyr::mutate(label = as.factor(label)) %\u0026gt;%\rdplyr::full_join(., dtw_result, by = \u0026quot;label\u0026quot;) %\u0026gt;% mutate(label = factor(label, levels = rev(as.character(labels_order)))) %\u0026gt;%\rggplot(aes(x = rundatelocal, y = value, colour = as.factor(cluster))) +\rgeom_line() +\rgeom_area(aes(fill = as.factor(cluster))) +\rcoord_cartesian(ylim = c(0,1)) +\rscale_y_continuous(name = \u0026quot;Average power density\u0026quot;, breaks = seq(0, 1, by = 1)) +\rscale_x_continuous(name = \u0026quot;Period (days)\u0026quot;) +\rfacet_wrap(~label, ncol = 1, strip.position=\u0026quot;left\u0026quot;) + guides(color=FALSE, fill = FALSE) +\rtheme_bw() + theme(strip.background = element_blank(), strip.text = element_blank())\r#\rplt_list \u0026lt;- list(p2, p1)\rplt_layout \u0026lt;- rbind(c(NA, 2),\rc(1, 2),\rc(NA, 2))\r#\rgrid.arrange(grobs = plt_list, layout_matrix = plt_layout, heights = c(0.04, 1, 0.05))\rThis frequency decomposition looks amazing but be careful because the power frequency are average and as stated in “WaveletComp 1.1:A guided tour through the R package”, “The average power plot cannot distinguish between consecutive periods and overlapping periods”. This is annoying but average power is definitely a first step toward a nice classification of training plan patterns.\n\r\r","date":1538006400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538006400,"objectID":"0a1826fc025f845a763ae67a24d65bc6","permalink":"/post/time-series-clustering-with-dynamic-time-warping-part-2/","publishdate":"2018-09-27T00:00:00Z","relpermalink":"/post/time-series-clustering-with-dynamic-time-warping-part-2/","section":"post","summary":"Like every good movies, my previous blog post “Time series clustering with Dynamic Time Warping” deserves a sequel. In this Part 2, I will have a look at the athletes’ training plan for a marathon. Because marathons are such a demanding performance, most of athletes have a specific training plan to follow in order to be prepared. Many different training plan can be found on the web such as this one from the website www.","tags":[],"title":"Time series clustering with Dynamic Time Warping (Part 2)","type":"post"},{"authors":null,"categories":[],"content":"Recently I was asked to make a short presentation about how to introduce the idea of statistical test and statistical significance to students in marketing. The timing was very good because I just had red a blog post written by Stephen B. Heard called Why do we make statistics so hard for our students? which is exactly the way to follow. So I taken the main idea of this post and made a short presentation with R that you can find here:\n\rI’ve also taken a simple meme which looks very trendy on the net. A great sentence by W. Edwards Deming “Without data you’re just another person with an opinion”. It’s simple but it is the reason why Statistics are very important not only in academia but also in companies.\nPS: Special thanks to Tim Mastny for his blog post about how to host R presentation in a blogdown\n","date":1536796800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536796800,"objectID":"ecbe24f0906a5b6683f1dee3db1b76fb","permalink":"/post/a-simple-introduction-to-statistical-test-and-statistical-significance/","publishdate":"2018-09-13T00:00:00Z","relpermalink":"/post/a-simple-introduction-to-statistical-test-and-statistical-significance/","section":"post","summary":"Recently I was asked to make a short presentation about how to introduce the idea of statistical test and statistical significance to students in marketing. The timing was very good because I just had red a blog post written by Stephen B. Heard called Why do we make statistics so hard for our students? which is exactly the way to follow. So I taken the main idea of this post and made a short presentation with R that you can find here:","tags":[],"title":"A simple introduction to statistical test and statistical significance","type":"post"},{"authors":null,"categories":[],"content":"Many solutions for clustering time series are available with R and as usual the web is full of nice tutorials like Thomas Girke’s blog post, Rafael Irizarry and Michael Love’s book, Andrew B. Collier’s blog post, Peter Laurinec’s blog post, Dylan Glotzer’s lecture or Ana Rita Marques’s module.\nDynamic Time Warping (DTW) is one of these solutions. The main advantage of DTW is the possibility to group time series according their patterns or shapes even if these patterns are not synchronized (lag).\nAs far as I know the two main packages which allow time series clustering with DTW are TSclust by Pablo Montero Manso and José Antonio Vilar and dtwclust by Alexis Sarda-Espinosa. These packages are very simple but powerful tools to analyse time series. However when it comes to analyse real data, I found difficult to understand how the clustering is working. To make this process clearer I’m going to simulate two groups of time series and to check if whether or not the DTW clustering can differentiate them.\nList of packages needed\rlibrary(dplyr) # data wrangling\rlibrary(ggplot2) # grammar of graphics\rlibrary(gridExtra) # merge plots\rlibrary(ggdendro) # dendrograms\rlibrary(gplots) # heatmap\rlibrary(tseries) # bootstrap\rlibrary(TSclust) # cluster time series\rlibrary(dtwclust) # cluster time series with dynamic time warping\r\rData simulation\rLet’s imagine two people running a marathon, one had a classic run with a pace increasing with the time and the other had a very bad experience (e.g. “hitting the wall”) with a jump in the pace which indicates a significant slow down in the second part of the run. The best is to have real data to analyse but it can be very useful to simulate these pattern in order to assess the clustering efficiency.\nA simple way to simulate these time series is to use the sine function and to add a random noise in order to make it more credible.\n# classic run\rnoise \u0026lt;- runif(420) # random noise\rx \u0026lt;- seq(1,420) # 42km with a measure every 100m\rpace_min \u0026lt;- 5 # min/km (corresponds to fast run)\rts_sim_classic_run \u0026lt;- (sin(x/10)+x/100+noise+pace_min) %\u0026gt;%\ras.ts(.)\rts.plot(ts_sim_classic_run, xlab = \u0026quot;Distance [x100m]\u0026quot;, ylab = \u0026quot;Differential pace [min/km]\u0026quot;, main = \u0026quot;Example of classic run\u0026quot;, ylim=c(0,25))\r# wall run\rnoise \u0026lt;- runif(210) # random noise\rx \u0026lt;- seq(1,210) # 21km with a measure every 100m pace_min \u0026lt;- 5 # min/km (corresponds to fast run)\rpace_wall \u0026lt;- 20 # min/km (corresponds to very slow run) ts_sim_part1 \u0026lt;- sin(x/5)+x/50+noise+pace_min\rts_sim_part2 \u0026lt;- sin(x/5)+noise+pace_wall\rts_sim_wall_run \u0026lt;- c(ts_sim_part1,ts_sim_part2) %\u0026gt;%\ras.ts(.)\rts.plot(ts_sim_wall_run, xlab = \u0026quot;Distance [x100m]\u0026quot;, ylab = \u0026quot;Differential pace [min/km]\u0026quot;, main = \u0026quot;Example of wall run\u0026quot;, ylim=c(0,25))\rA much nicer way would be to use ARIMA with an auto regressive model (AR).\npace_min \u0026lt;- 5 # min/km (corresponds to fast run)\rpace_wall \u0026lt;- 20 # min/km (corresponds to very slow run) # classic run\rts_sim_classic_run \u0026lt;- abs(arima.sim(n = 420, mean = 0.001, model = list(order = c(1,0,0), ar = 0.9))) + pace_min\rts.plot(ts_sim_classic_run, xlab = \u0026quot;Distance [x100m]\u0026quot;, ylab = \u0026quot;Differential pace [min/km]\u0026quot;, main = \u0026quot;Example of classic run\u0026quot;, ylim=c(0,25))\r# wall run\rts_sim_part1 \u0026lt;- abs(arima.sim(n = 210, model = list(order = c(1,0,0), ar = 0.9))) + pace_min\rts_sim_part2 \u0026lt;- ts(arima.sim(n = 210, model = list(order = c(1,0,0), ar = 0.9)) + pace_wall, start = 211,end =420)\rts_sim_wall_run \u0026lt;- ts.union(ts_sim_part1,ts_sim_part2)\rts_sim_wall_run\u0026lt;- pmin(ts_sim_wall_run[,1], ts_sim_wall_run[,2], na.rm = TRUE)\rts.plot(ts_sim_wall_run, xlab = \u0026quot;Distance [x100m]\u0026quot;, ylab = \u0026quot;Differential pace [min/km]\u0026quot;, main = \u0026quot;Example of wall run\u0026quot;, ylim=c(0,25))\r\rBootstrap\rNow we have two different runs, let’s bootstrap them (i.e. replicate with small differences) in order to have two groups of 5 individuals for each run type.\nts_sim_boot_classic \u0026lt;- ts_sim_classic_run %\u0026gt;%\rtseries::tsbootstrap(., nb=5, b=200, type = \u0026quot;block\u0026quot;) %\u0026gt;%\ras.data.frame(.) %\u0026gt;%\rdplyr::rename_all(funs(c(paste0(\u0026quot;classic_\u0026quot;,.))))\rts_sim_boot_wall \u0026lt;- ts_sim_wall_run %\u0026gt;%\rtseries::tsbootstrap(., nb=5, b=350, type = \u0026quot;block\u0026quot;) %\u0026gt;%\ras.data.frame(.) %\u0026gt;%\rdplyr::rename_all(funs(c(paste0(\u0026quot;wall_\u0026quot;,.))))\rts_sim_df \u0026lt;- cbind(ts_sim_boot_classic,ts_sim_boot_wall)\r\rHeatmap cluster\rEven if I’m a big fan of ggplot2 possibilities, some packages offer efficient ways to compute and plot data. For heatmaps I’m using the gplots package which displays time series with dendrograms is a single function. An overlook of all the heatmap possibilities can be found here\ndtw_dist \u0026lt;- function(x){dist(x, method=\u0026quot;DTW\u0026quot;)}\rts_sim_df %\u0026gt;%\ras.matrix() %\u0026gt;%\rgplots::heatmap.2 (\r# dendrogram control\rdistfun = dtw_dist,\rhclustfun = hclust,\rdendrogram = \u0026quot;column\u0026quot;,\rRowv = FALSE,\rlabRow = FALSE\r)\rWe can already see an accurate clustering between classic and wall runs but we are interested in DTW analysis so let’s implement TSclust and dtwclust packages.\n\rDTW cluster\rBoth TSclust and dtwclust are following the same steps:\nCalculating the difference between each time series using the DTW method (but many other distances can be calculated, see for example Montero \u0026amp; Vilar, 2014).\rCalculating hierarchical cluster analysis over these dissimilarities.\rPlotting a dendrogram to visually assess the cluster accuracy. The solution to plot the time series with the dendrogram was taken from Ian Hansel’s blog.\r\rUsing TSclust\r# cluster analysis\rdist_ts \u0026lt;- TSclust::diss(SERIES = t(ts_sim_df), METHOD = \u0026quot;DTWARP\u0026quot;) # note the dataframe must be transposed\rhc \u0026lt;- stats::hclust(dist_ts, method=\u0026quot;complete\u0026quot;) # meathod can be also \u0026quot;average\u0026quot; or diana (for DIvisive ANAlysis Clustering)\r# k for cluster which is 2 in our case (classic vs. wall)\rhclus \u0026lt;- stats::cutree(hc, k = 2) %\u0026gt;% # hclus \u0026lt;- cluster::pam(dist_ts, k = 2)$clustering has a similar result\ras.data.frame(.) %\u0026gt;%\rdplyr::rename(.,cluster_group = .) %\u0026gt;%\rtibble::rownames_to_column(\u0026quot;type_col\u0026quot;)\rhcdata \u0026lt;- ggdendro::dendro_data(hc)\rnames_order \u0026lt;- hcdata$labels$label\r# Use the folloing to remove labels from dendogram so not doubling up - but good for checking hcdata$labels$label \u0026lt;- \u0026quot;\u0026quot;\rp1 \u0026lt;- hcdata %\u0026gt;%\rggdendro::ggdendrogram(., rotate=TRUE, leaf_labels=FALSE)\rp2 \u0026lt;- ts_sim_df %\u0026gt;%\rdplyr::mutate(index = 1:420) %\u0026gt;%\rtidyr::gather(key = type_col,value = value, -index) %\u0026gt;%\rdplyr::full_join(., hclus, by = \u0026quot;type_col\u0026quot;) %\u0026gt;% mutate(type_col = factor(type_col, levels = rev(as.character(names_order)))) %\u0026gt;% ggplot(aes(x = index, y = value, colour = cluster_group)) +\rgeom_line() +\rfacet_wrap(~type_col, ncol = 1, strip.position=\u0026quot;left\u0026quot;) + guides(color=FALSE) +\rtheme_bw() + theme(strip.background = element_blank(), strip.text = element_blank())\rgp1\u0026lt;-ggplotGrob(p1)\rgp2\u0026lt;-ggplotGrob(p2) grid.arrange(gp2, gp1, ncol=2, widths=c(4,2))\rAs expected, The results of TSclustshow two different groups, one with the classic runs and one with wall runs. However we can see that wall runs are not sorted perfectly according their shape. Let’s have a look at dtwclust to see if the results are similar.\n\rUsing dtwclust\rThe main asset of dtwclust is the possibility to customize the DTW clustering. For more details about all the possibilities, I suggest to have a look at the dtwclust package vignette.\ncluster_dtw_h2 \u0026lt;- dtwclust::tsclust(t(ts_sim_df), type = \u0026quot;h\u0026quot;, k = 2, distance = \u0026quot;dtw\u0026quot;, control = hierarchical_control(method = \u0026quot;complete\u0026quot;),\rpreproc = NULL, args = tsclust_args(dist = list(window.size = 5L)))\rhclus \u0026lt;- stats::cutree(cluster_dtw_h2, k = 2) %\u0026gt;% # hclus \u0026lt;- cluster::pam(dist_ts, k = 2)$clustering has a similar result\ras.data.frame(.) %\u0026gt;%\rdplyr::rename(.,cluster_group = .) %\u0026gt;%\rtibble::rownames_to_column(\u0026quot;type_col\u0026quot;)\rhcdata \u0026lt;- ggdendro::dendro_data(cluster_dtw_h2)\rnames_order \u0026lt;- hcdata$labels$label\r# Use the folloing to remove labels from dendogram so not doubling up - but good for checking hcdata$labels$label \u0026lt;- \u0026quot;\u0026quot;\rp1 \u0026lt;- hcdata %\u0026gt;%\rggdendro::ggdendrogram(., rotate=TRUE, leaf_labels=FALSE)\rp2 \u0026lt;- ts_sim_df %\u0026gt;%\rdplyr::mutate(index = 1:420) %\u0026gt;%\rtidyr::gather(key = type_col,value = value, -index) %\u0026gt;%\rdplyr::full_join(., hclus, by = \u0026quot;type_col\u0026quot;) %\u0026gt;% mutate(type_col = factor(type_col, levels = rev(as.character(names_order)))) %\u0026gt;% ggplot(aes(x = index, y = value, colour = cluster_group)) +\rgeom_line() +\rfacet_wrap(~type_col, ncol = 1, strip.position=\u0026quot;left\u0026quot;) + guides(color=FALSE) +\rtheme_bw() + theme(strip.background = element_blank(), strip.text = element_blank())\rgp1\u0026lt;-ggplotGrob(p1)\rgp2\u0026lt;-ggplotGrob(p2) grid.arrange(gp2, gp1, ncol=2, widths=c(4,2))\rNow with the cluster are well distributed between classic and wall runs but also inside the clusters where similar shapes appears to be grouped together.\nIt is possible to modify some argument in order to perform this hierarchical DTW clustering based on z-scores with centroid based on the built-in “shape_extraction” function.\ncluster_dtw_h2 \u0026lt;- dtwclust::tsclust(t(ts_sim_df), type = \u0026quot;h\u0026quot;, k = 2L,\rpreproc = zscore,\rdistance = \u0026quot;dtw\u0026quot;, centroid = shape_extraction,\rcontrol = hierarchical_control(method = \u0026quot;complete\u0026quot;))\rhclus \u0026lt;- stats::cutree(cluster_dtw_h2, k = 2) %\u0026gt;% # hclus \u0026lt;- cluster::pam(dist_ts, k = 2)$clustering has a similar result\ras.data.frame(.) %\u0026gt;%\rdplyr::rename(.,cluster_group = .) %\u0026gt;%\rtibble::rownames_to_column(\u0026quot;type_col\u0026quot;)\rhcdata \u0026lt;- ggdendro::dendro_data(cluster_dtw_h2)\rnames_order \u0026lt;- hcdata$labels$label\r# Use the folloing to remove labels from dendogram so not doubling up - but good for checking hcdata$labels$label \u0026lt;- \u0026quot;\u0026quot;\rp1 \u0026lt;- hcdata %\u0026gt;%\rggdendro::ggdendrogram(., rotate=TRUE, leaf_labels=FALSE)\rp2 \u0026lt;- ts_sim_df %\u0026gt;%\rdplyr::mutate(index = 1:420) %\u0026gt;%\rtidyr::gather(key = type_col,value = value, -index) %\u0026gt;%\rdplyr::full_join(., hclus, by = \u0026quot;type_col\u0026quot;) %\u0026gt;% mutate(type_col = factor(type_col, levels = rev(as.character(names_order)))) %\u0026gt;% ggplot(aes(x = index, y = value, colour = cluster_group)) +\rgeom_line() +\rfacet_wrap(~type_col, ncol = 1, strip.position=\u0026quot;left\u0026quot;) + guides(color=FALSE) +\rtheme_bw() + theme(strip.background = element_blank(), strip.text = element_blank())\rgp1\u0026lt;-ggplotGrob(p1)\rgp2\u0026lt;-ggplotGrob(p2) grid.arrange(gp2, gp1, ncol=2, widths=c(4,2))\rBased on dtwclust package vignette, it is possible to register a new DTW function adapted to normalized and asymmetric DTW.\n# Normalized DTW\rndtw \u0026lt;- function(x, y, ...) {\rdtw(x, y, ...,\rstep.pattern = asymmetric,\rdistance.only = TRUE)$normalizedDistance\r}\r# Register the distance with proxy\rproxy::pr_DB$set_entry(FUN = ndtw, names = c(\u0026quot;nDTW\u0026quot;),\rloop = TRUE, type = \u0026quot;metric\u0026quot;, distance = TRUE,\rdescription = \u0026quot;Normalized, asymmetric DTW\u0026quot;)\r# Partitional clustering\rcluster_dtw_h2 \u0026lt;- dtwclust::tsclust(t(ts_sim_df), k = 2L,distance = \u0026quot;nDTW\u0026quot;)\rplot(cluster_dtw_h2)\rEven if it looks great with sine simulated data, it is not very accurate with ARIMA models. Moreover I haven’t been able to extract the dendrogram from this last “cluster_dtw_h2” object because of the partitional clustering process but one can be interested in the distance matrix provided in “cluster_dtw_h2” object.\nAfter this short analysis with Dynamic Time Warping, the next steps will be to increase the difference between the time series to check the clustering accuracy and obviously to test it with real data.\n\r\r","date":1536192000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536192000,"objectID":"a6988f08c9d9c163fc3fcbf64887e8fa","permalink":"/post/time-series-clustering-with-dynamic-time-warp/","publishdate":"2018-09-06T00:00:00Z","relpermalink":"/post/time-series-clustering-with-dynamic-time-warp/","section":"post","summary":"Many solutions for clustering time series are available with R and as usual the web is full of nice tutorials like Thomas Girke’s blog post, Rafael Irizarry and Michael Love’s book, Andrew B. Collier’s blog post, Peter Laurinec’s blog post, Dylan Glotzer’s lecture or Ana Rita Marques’s module.\nDynamic Time Warping (DTW) is one of these solutions. The main advantage of DTW is the possibility to group time series according their patterns or shapes even if these patterns are not synchronized (lag).","tags":[],"title":"Time series clustering with Dynamic Time Warping","type":"post"},{"authors":null,"categories":[],"content":"Finally! My first post to my website is about to be live on the web! I’m always amazed by the possibilities offered by R and Rstudio and my first lines will thank this huge community which make the awesomeness real. However it’s not always easy to use and to apply these magnificent tools. Publishing a blogdown is a good example of a process that looks easy on the first sight but which can be tricky. Here are some insights from my experience in publishing a research blog from blogdown.\nFirst steps with blogdown\rThe blogdown package is very well documented and if you are intended to publish your own websites the best approach is to have a look at the bookdown made by Yihui Xie, Amber Thomas and Alison Presmanes Hill blogdown: Creating Websites with R Markdown.\nSeveral tutorials are available to help new users in this case:\n\rA blog post writen by Alison Presmanes Hill, Up and running with blogdown, is a very good first step to blogdown. The post is well documented and will help to solve most of the major problems to setup a website.\rThe talk given by Yihui Xie at the rstudio::conf 2018, Create and maintain websites with R Markdown and blogdown, is short and very well presented.\rThe youtube tutorial by John Muschelli, Making a Website with Blogdown, presents all the steps from building a website to publishing it on netlify.com.\r\r\rProblem solving\rEven if the authors of blogdown made it very easy to publish a blog from Rstudio, some problem can be encountered while following the basic steps. Here is my experience in troubleshooting some of the problems that can happen.\nPrerequisite\rIn order to avoid the majority of the problems that may happen, it is essential to have the latest versions of R, Rstudio, blogdown package (don’t hesitate to use its GitHub version devtools::install_github(\u0026quot;rstudio/blogdown\u0026quot;)) and Hugo (blogdown::update_hugo()). Like mine, if the process of publishing a blogdown takes several weeks, upgrading to the latest version for every try can slove a lot of problems.\n\rCreating a GitHub connection\rIf one wants to make blogdown live on the web, a GitHub integration is the way to go according to me. Two routes are possible:\nCreating a blogdown project from Rstudio and then uploading the project on GitHub. Rstudio GUI is one of its main asset and creating a blogdown project from Rstudio is very easy but the connection with GitHub has to be done afterward which can lead to several problems when committing the changes.\rCreating an empty repo on GitHub, then creating a new project with version control on Rstudio and use the function blogdown::build_site() in this new project. This solution doesn’t look as straight forward but once it is done, the connection with GitHub is very stable.\r\r\rInstalling a new theme\rWhen it comes to build the site, it is possible to specify the theme you want to use with blogdown::new_site(theme = \u0026quot;gcushen/hugo-academic\u0026quot;). Even if the default theme is nice, researchers and students can find the theme “academic” more suitable. But be sure to have installed a version of Hugo that corresponds with the theme version of Hugo.\nAfter this initial command, the template website should be displayed in Rstudio viewer. If you have to close the project it is possible to relaunch this view using the Serve Site shortcut in Rstudio Addins or by using blogdown::serve_site(). Next step is the uploading of this template website in GitHub.\n\rMaking GitHub commit and push\rA big advantage of GitHub integration is that when your website is live on the web, any new post or new content is automatically uploaded with simple commit and push from Rstudio project. Rstudio provides a nice interface to do these commit and push to GitHub without using any command lines which is great for new coders and/or windows users. However with the initial commit and push of a blogdown I didn’t manage to use Rstudio GUI resulting of endless lags and multiple reboots. The solution is to use github commit and push from command lines.\nif you are new to command lines don’t be afraid, it is very easy:\nIf your project is linked with GitHub, that means Git is also installed and Git comes with a CMD prompt that can be used for manual commit and push to GitHub.\rChange the directory\r\rfrom C:\\Users\\MyName\u0026gt;\rto C:\\Users\\MyName\\MyFolderName\\MyBlogdownProjectName\u0026gt;\rusing cd .\\MyFolderName\\MyBlogdownProjectName.\r\rAdd all changes with the command git add -A.\rCommit these changes with the command git commit -m \u0026quot;initial commit text\u0026quot;.\rPush these changes to GitHub with the command git push.\r\rNote: these commands are the most basic ones, it can me more complicated to add only specific files or to push from another branch but in these cases you can easily find the commands on the web.\n\rPublishing the template to Netlify\rOnce this initial commit is done, it is possible to make the template live on Netlify. I think it is a good idea to not modify the template yet in order to first check how Netlify is handling the template website.\nOn Netlify, with GitHub login and password, it is easy to find you repo and to deploy the website. However Netlify will analyse the project and this can result in more errors and problems. The biggest problem that I had was solved very easily with the genius Mara Averick and her blog post Updating your version of Hugo for blogdown on Netlify. I should create a blog dedicated to how amazing Mara is and as usual she solved a massive problem. Indeed, Hugo’s theme have specific minimum Hugo version to use but even Rstudio is using the latest version to build the website, Netlify needs to know which version to use. The correct version must be set as a New variable with the key to HUGO_VERSION. Then the magic happens and the website is deployed to the world. the first URL address of the website is quite complicated but Netlify allows to change it for free.\n\rChanging the content of the template\rLast but not least, the website you have just published needs to be filled with your own content. The first step will be to replace all the lines in the sub-folder home with your own data and to delete all the posts, publications, citations, images, etc. inside the template. However it is still possible to broke the website by deleting a useful link. In this case I have two advice:\nKeep a version of the template in case you need to get back one of the files and then understanding why deleting these information is braking the website.\rDo not delete the files called _index.md, they are very useful to create the public site of the website.\r\r\r\rWhat’s next?\rThe websites created with the blogdown package from the R and stats community are united in a project called rbind. I hope to be one day expert enough to be part of this community and hopefully with my tricks and tips, you will as well ;)\n\r","date":1536019200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536019200,"objectID":"4325d7054682143c838324406f820b55","permalink":"/post/publishing-blogdown-some-insights-from-my-own-experience/","publishdate":"2018-09-04T00:00:00Z","relpermalink":"/post/publishing-blogdown-some-insights-from-my-own-experience/","section":"post","summary":"Finally! My first post to my website is about to be live on the web! I’m always amazed by the possibilities offered by R and Rstudio and my first lines will thank this huge community which make the awesomeness real. However it’s not always easy to use and to apply these magnificent tools. Publishing a blogdown is a good example of a process that looks easy on the first sight but which can be tricky.","tags":[],"title":"Publishing blogdown, some insights from my own experience","type":"post"},{"authors":null,"categories":null,"content":"\u0026hellip;\n","date":1530140400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530140400,"objectID":"18d05a63a1c8d7ed973cc51838494e41","permalink":"/privacy/","publishdate":"2018-06-28T00:00:00+01:00","relpermalink":"/privacy/","section":"","summary":"\u0026hellip;","tags":null,"title":"Privacy Policy","type":"page"},{"authors":["Damien Dupré","Nicole Andelic","Anna Zajac","Gawain Morrison","Gary McKeown"],"categories":null,"content":"","date":1517443200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517443200,"objectID":"b310d181aea2f2e2023bacd44f0cda8a","permalink":"/publication/2018-socialmedia-psyarxiv/","publishdate":"2018-02-01T00:00:00Z","relpermalink":"/publication/2018-socialmedia-psyarxiv/","section":"publication","summary":"Sharing personal information is an important way of communicating on social media. Among the information possibly shared, new sensors and tools allow people to share emotion information via facial emotion recognition. This paper questions whether people are prepared to share personal information such as their own emotion on social media. In the current study we examined how factors such as felt emotion, motivation for sharing on social media as well as personality affected participants’ willingness to share self-reported emotion or facial expression online. By carrying out a GLMM analysis, this study found that participants’ willingness to share self-reported emotion and facial expressions was influenced by their personality traits and the motivation for sharing their emotion information that they were given. From our results we can conclude that the estimated level of privacy for certain emotional information, such as facial expression, is influenced by the motivation for sharing the information online.","tags":null,"title":"The effect of personality and social context on willingness to share emotion information on social media","type":"publication"},{"authors":["Damien Dupré","Michel Dubois","Anna Tcherkassof"],"categories":null,"content":"","date":1501545600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501545600,"objectID":"6066820de43f1977f9eb1817c7d34a8f","permalink":"/publication/2017-acceptance-pto/","publishdate":"2017-08-01T00:00:00Z","relpermalink":"/publication/2017-acceptance-pto/","section":"publication","summary":"To anticipate a product commercial success, companies aim to ensure that product's characteristics are involving users and triggering a positive first user experience as well as all along product's life span. Among these characteristics, triggering users’ emotions is particularly relevant. This article aims to present the different approaches integrating the emotion generated by products. In order to illustrate the emotional potential of certain products a selection of 14 photographs of products was evaluated by 87 participants. Results reveal a significant correlation between cognitive, motivational and subjective components of emotions. A reflexion about the integration of cognitive appraisal assessment and motivational action readiness evaluation into a wilder emotional model is provided. Thus, emotions triggered by a product appear to be a stake for designers and an important variable to introduce in acceptability or user experience models.","tags":null,"title":"Role of emotions in product acceptance: Evaluation of the cognitive, motivational and subjective component","type":"publication"},{"authors":null,"categories":null,"content":"SYMPOSIUM 2: Affect Recognition in Humans versus Machines: Current Issues and Future Challenges Convener: Eva Krumhuber, University College London, UK\nABSTRACT: Automatic facial expression recognition systems can provide important information about our emotions and how they change over time. While the use of automatic systems has seen a steady increase over the last years, their classification results have not yet been systematically compared. The aim of this research was to test commercial software packages from Affectiva, Kairos and Microsoft companies in terms of their recognition accuracy. For this, we focused on spontaneous and dynamic facial expressions as provided by the DynEmo database –Disgust, Fear, Joy, and Surprise. In order to compare the classification results, we calculated the systems’ ratio of True positives (only the target label is recognised), False positives (the target label as well as a non-target label is recognised), True negatives (no label is recognised) and False negatives (target label is not recognised whereas a non-target label is). The results of the comparison between the systems showed comparable detection rates in term of True positives and False positives. However, their detection rates of False negatives and True negatives significantly differed between the different recognition systems. Specifically, systems were not equal in their tendency to detect non-target labels erroneously as well as in their tendency to not detect any emotion label. When examining emotion recognition accuracy for each video/emotion, videos with higher recognition accuracy were those that depicted as joyful facial expression. Other facial expressions resulted in a proportion of target emotion detection statistically equal or lower than the detection of non-target emotion. These results suggest that systems are not equivalent in their ability to detect specific spontaneous emotions. Therefore, users of such systems have to be aware of the strengths as well as of the potential limits of the data provided by automatic emotion recognition systems.\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"829168eaa641e73affffe98045950239","permalink":"/talk/2018-cere/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/2018-cere/","section":"talk","summary":"SYMPOSIUM 2: Affect Recognition in Humans versus Machines: Current Issues and Future Challenges Convener: Eva Krumhuber, University College London, UK\nABSTRACT: Automatic facial expression recognition systems can provide important information about our emotions and how they change over time. While the use of automatic systems has seen a steady increase over the last years, their classification results have not yet been systematically compared. The aim of this research was to test commercial software packages from Affectiva, Kairos and Microsoft companies in terms of their recognition accuracy.","tags":null,"title":"A Comparison of Three Commercial Systems for Automatic Recognition of Spontaneous Facial Expressions","type":"talk"},{"authors":null,"categories":null,"content":"ABSTRACT:\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"ec18e2d1833edc04351fa65b592e3653","permalink":"/talk/2018-percom/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/2018-percom/","section":"talk","summary":"ABSTRACT:","tags":null,"title":"Accuracy of three commercial automatic emotion recognition systems across different individuals and their facial expressions","type":"talk"},{"authors":null,"categories":null,"content":"ABSTRACT:\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"afb9ac9d32b42efd8c5ce6de8b90bbe8","permalink":"/talk/2014-cere/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/2014-cere/","section":"talk","summary":"ABSTRACT:","tags":null,"title":"Are approach-avoidance relevant cues of the Emotional User eXperience? Case studies with innovative products","type":"talk"},{"authors":null,"categories":null,"content":"ABSTRACT: With the development of wearable sensors, it is now possible to assess the dynamic progression of physiological rhythms such as heart rate, breathing rate or galvanic skin response in ways and places and during certain activities that were previously not possible due to cost and reliability. This paper investigates the physiological changes when participating in a zipline activity. Despite the advances in sensor technology, the statistical analysis of such physiological signals remains a challenge for data analysts. This paper presents a workflow encompassing the whole process with the goal of obtaining a range of best fitting models to analyse the patterns given by these measurements “in the wild”.\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"162546dfedc5ea418731cbad6a829a79","permalink":"/talk/2017-aisb/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/2017-aisb/","section":"talk","summary":"ABSTRACT: With the development of wearable sensors, it is now possible to assess the dynamic progression of physiological rhythms such as heart rate, breathing rate or galvanic skin response in ways and places and during certain activities that were previously not possible due to cost and reliability. This paper investigates the physiological changes when participating in a zipline activity. Despite the advances in sensor technology, the statistical analysis of such physiological signals remains a challenge for data analysts.","tags":null,"title":"Dynamic Analysis of Automatic Emotion Recognition Using Generalized Additive Mixed Models","type":"talk"},{"authors":null,"categories":null,"content":"ABSTRACT: The analysis of facial expressions is currently a favoured method of inferring experienced emotion, and consequently significant efforts are currently being made to develop improved facial expression recognition techniques. Among these new techniques, those which allow the automatic recognition of facial expression appear to be most promising. This paper presents a new method of facial expression analysis with a focus on the continuous evolution of emotions using Generalized Additive Mixed Models (GAMM) and Significant Zero Crossing of the Derivatives (SiZer). The time-series analysis of the emotions experienced by participants watching a series of three different online videos suggests that analysis of facial expressions at the overall level may lead to misinterpretation of the emotional experience whereas non-linear analysis allows the significant expressive sequences to be identified.\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"bb71d58a6ea9cc17ac083952cd366d61","permalink":"/talk/2018-bhci/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/2018-bhci/","section":"talk","summary":"ABSTRACT: The analysis of facial expressions is currently a favoured method of inferring experienced emotion, and consequently significant efforts are currently being made to develop improved facial expression recognition techniques. Among these new techniques, those which allow the automatic recognition of facial expression appear to be most promising. This paper presents a new method of facial expression analysis with a focus on the continuous evolution of emotions using Generalized Additive Mixed Models (GAMM) and Significant Zero Crossing of the Derivatives (SiZer).","tags":null,"title":"Dynamic Analysis of Automatic Facial Expressions Recognition ‘in the Wild’ Using Generalized Additive Mixed Models and Significant Zero Crossing of the Derivatives","type":"talk"},{"authors":null,"categories":null,"content":"ABSTRACT: With the development of wearable sensors, it is now possible to assess the dynamic progression of physiological rhythms such as heart rate, breathing rate or galvanic skin response in ways and places that were previously impractical. This paper presents a new application that synchronizes the emotional patterns from these time-series in order to model athletes’ emotion during physical activity. This data analysis computes a best-fitting model for analyzing the patterns given by these measurements “in the wild”. The recording setup used to measure and synchronize multiple biometric physiological sensors can be called a BAN (Body Area Network) of personal measurements. By monitoring physical activity, it is now possible to calculate optimal patterns for managing athletes’ emotion. The data provided here are not restricted by a lab environment but close to the “ground truth” of ecologically valid physiological changes. The data allow the provision of accurate feedback to athletes about their emotion (e.g. in cases such as an unexpected increase or an expected decrease of physiological activity).\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"ade35b7546c48c5d89a3a9910b1b1094","permalink":"/talk/2017-ahfe/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/2017-ahfe/","section":"talk","summary":"ABSTRACT: With the development of wearable sensors, it is now possible to assess the dynamic progression of physiological rhythms such as heart rate, breathing rate or galvanic skin response in ways and places that were previously impractical. This paper presents a new application that synchronizes the emotional patterns from these time-series in order to model athletes’ emotion during physical activity. This data analysis computes a best-fitting model for analyzing the patterns given by these measurements “in the wild”.","tags":null,"title":"Dynamic Model of Athletes’ Emotions Based on Wearable Devices","type":"talk"},{"authors":null,"categories":null,"content":"ABSTRACT: User eXperience studies with products, systems or services have significantly increased in companies in order to anticipate their commercial success. Among the user experience dimensions, emotions are predominant. However User eXperience studies used several concepts to refer to emotions and current measures still have some flaws. Consequently, this doctoral project aims firstly to provide a multi-componential approach of emotions based on a psychological view, and secondly to provide Affective Computing solutions in order to evaluate emotions in User eXperience studies. Through a study using hand-gesture interface devices, three components of users\u0026rsquo; emotions were simultaneously measured with self-reports: the subjective, cognitive and motivational components. The results point out the possibility of measuring different components in order to gain a better understanding of emotions triggered by products. They also point out that self-reports measures could be improved with Affective Computing solutions. In this perspective, two emotion assessment tools were developed: Oudjat and EmoLyse.\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"a31d6512260e0f4ad9a2dd62ee4b2b98","permalink":"/talk/2015-acii/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/2015-acii/","section":"talk","summary":"ABSTRACT: User eXperience studies with products, systems or services have significantly increased in companies in order to anticipate their commercial success. Among the user experience dimensions, emotions are predominant. However User eXperience studies used several concepts to refer to emotions and current measures still have some flaws. Consequently, this doctoral project aims firstly to provide a multi-componential approach of emotions based on a psychological view, and secondly to provide Affective Computing solutions in order to evaluate emotions in User eXperience studies.","tags":null,"title":"Emotions triggered by innovative products, A multi-componential approach of emotions for User eXperience tools","type":"talk"},{"authors":null,"categories":null,"content":"ABSTRACT:\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"060b6511ae3c46a0d81d65e321f8e8cf","permalink":"/talk/2016-aiptlf/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/2016-aiptlf/","section":"talk","summary":"ABSTRACT:","tags":null,"title":"Etude de l’expérience utilisateur émotionnelle: Quels sont les impacts des émotions suscitées des produits innovants sur les perceptions des utilisateurs","type":"talk"},{"authors":null,"categories":null,"content":"ABSTRACT: In supporting the visual-mediated emotional recognition, little research has centred on analysing the effect of presenting different combinatorial facial designs. Moreover, in the theoretical field of emotions, research on the recognition of emotional facial expressions (EFE) is mainly based on static and posed databases tested in unnatural contexts (explicit recognition task of an emotion). Our research has constructed and validated a database, DynEmo, with dynamic and spontaneous emotional facial expressions. So different facial interface designs (whole face, zoomed face, eyes + mouth, whole face + mouth, whole face + eyes, etc., n = 11) are experimentally compared to find their impact in terms of emotional recognition. The results show the facial interface design relevance in terms of emotional recognition. The application of this work is transferable to facial interfaces useful for video-mediated interaction.\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"a57b931c51d65917e53b1642228dcafe","permalink":"/talk/2010-eiac/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/2010-eiac/","section":"talk","summary":"ABSTRACT: In supporting the visual-mediated emotional recognition, little research has centred on analysing the effect of presenting different combinatorial facial designs. Moreover, in the theoretical field of emotions, research on the recognition of emotional facial expressions (EFE) is mainly based on static and posed databases tested in unnatural contexts (explicit recognition task of an emotion). Our research has constructed and validated a database, DynEmo, with dynamic and spontaneous emotional facial expressions.","tags":null,"title":"Interface faciale émotionnelle : Les effets des différentes modalités de presentation","type":"talk"},{"authors":null,"categories":null,"content":"ABSTRACT:\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"359f4ae252793bee69ab71b62da38dd8","permalink":"/talk/2012-de/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/2012-de/","section":"talk","summary":"ABSTRACT:","tags":null,"title":"Measuring emotional states and behavioral responses to innovative products","type":"talk"},{"authors":null,"categories":null,"content":"ABSTRACT: With the development of wearable sensors, it is now possible to assess the dynamic progression of physiological rhythms such as heart rate, breathing rate or galvanic skin response in ways and places and during certain activities that were previously not possible due to cost and reliability. This paper investigates the physiological changes when participating in a zipline activity. Despite the advances in sensor technology, the statistical analysis of such physiological signals remains a challenge for data analysts. This paper presents a workflow encompassing the whole process with the goal of obtaining a range of best fitting models to analyse the patterns given by these measurements “in the wild”.\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"964a4c5a5dda77f0f2aaf0bdb0f7e5d1","permalink":"/talk/2018-mb/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/2018-mb/","section":"talk","summary":"ABSTRACT: With the development of wearable sensors, it is now possible to assess the dynamic progression of physiological rhythms such as heart rate, breathing rate or galvanic skin response in ways and places and during certain activities that were previously not possible due to cost and reliability. This paper investigates the physiological changes when participating in a zipline activity. Despite the advances in sensor technology, the statistical analysis of such physiological signals remains a challenge for data analysts.","tags":null,"title":"Multivariate Body Area Network of Physiological Measures “In the Wild”: A case study with zipline activity","type":"talk"},{"authors":null,"categories":null,"content":"ABSTRACT:\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"b2dbb3283c22fe9c4ed8e3a713f03ca4","permalink":"/talk/2010-cere/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/2010-cere/","section":"talk","summary":"ABSTRACT:","tags":null,"title":"On-line recognition of dynamic and spontaneous facial expression","type":"talk"},{"authors":null,"categories":null,"content":"ABSTRACT:\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"607b381a14579ed50fe8b980f8150a61","permalink":"/talk/2017-isre/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/2017-isre/","section":"talk","summary":"ABSTRACT:","tags":null,"title":"Physiological correlates of Emotions “In The Wild”: A case study with mountain bikers","type":"talk"},{"authors":null,"categories":null,"content":"ABSTRACT:\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"31b7bd8b8b67d213a167fcbbef50f7ed","permalink":"/talk/2014-wcfee/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/2014-wcfee/","section":"talk","summary":"ABSTRACT:","tags":null,"title":"Spontaneous and dynamic emotional facial expressions reflect action readiness","type":"talk"},{"authors":null,"categories":null,"content":"ABSTRACT: Sharing personal information is an important way of communicating on social media. Among the information possibly shared, new sensors and tools allow people to share emotion information via facial emotion recognition. This paper questions whether people are prepared to share personal information such as their own emotion on social media. In the current study we examined how factors such as felt emotion, motivation for sharing on social media as well as personality affected participants’ willingness to share self-reported emotion or facial expression online. By carrying out a Generalized Linear Mixed Model analysis, this study found that participants’ willingness to share self-reported emotion and facial expressions was influenced by their personality traits and the motivation for sharing their emotion information that they were given. From our results we can conclude that the estimated level of privacy for certain emotional information, such as facial expression, is influenced by the motivation for sharing the information online.\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"784e4c5f7518565841d04eb2cc6dff26","permalink":"/talk/2018-dsaa/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/2018-dsaa/","section":"talk","summary":"ABSTRACT: Sharing personal information is an important way of communicating on social media. Among the information possibly shared, new sensors and tools allow people to share emotion information via facial emotion recognition. This paper questions whether people are prepared to share personal information such as their own emotion on social media. In the current study we examined how factors such as felt emotion, motivation for sharing on social media as well as personality affected participants’ willingness to share self-reported emotion or facial expression online.","tags":null,"title":"Willingness to Share Emotion Information on Social Media: Influence of Personality and Social Context","type":"talk"},{"authors":null,"categories":null,"content":"DynEmo is a database available to the scientific community (https://dynemo.univ-grenoble-alpes.fr/). It contains dynamic and natural emotional facial expressions (EFEs) displaying subjective affective states rated by both the expresser and observers. Methodological and contextual information is provided for each expression. This multimodal corpus meets psychological, ethical, and technical criteria. It is quite large, containing two sets of 233 and 125 recordings of EFE of ordinary Caucasian people (ages 25 to 65, 182 females and 176 males) filmed in natural but standardized conditions. In the Set 1, EFE recordings are associated with the affective state of the expresser (self-reported after the emotion inducing task, using dimensional, action readiness, and emotional labels items). In the Set 2, EFE recordings are both associated with the affective state of the expresser and with the time line (continuous annotations) of observers’ ratings of the emotions displayed throughout the recording. The time line allows any researcher interested in analysing non-verbal human behavior to segment the expressions into small emotion excerpts.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"dbb5c11de9e435bdeaf51c6a2aeb9209","permalink":"/project/dynemo/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/dynemo/","section":"project","summary":"DynEmo is a database available to the scientific community. It contains 358 dynamic and natural emotional facial expressions (EFEs) displaying subjective affective states rated by both the expresser and observers. Methodological and contextual information is provided for each expression. This multimodal corpus meets psychological, ethical, and technical criteria.","tags":["dynemo"],"title":"DynEmo","type":"project"},{"authors":null,"categories":null,"content":"LTfLL created next-generation educational services for learners and tutors, making extensive use of Language Technologies. The project created next-generation support and advice services to enhance individual and collaborative construction of knowledge in educational and organisational settings. The project made extensive use of language technologies and cognitive models in the services. The technical infrastructure allows deployment of these services in Personal Learning Environments (PLEs) as well as in institutional Learning Management Systems (LMSs). The validity of the research assumptions and their practical implementation has been tested and evaluated in realistic settings.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"67848cf8cea9d4ee7c06fd4d0dce39ef","permalink":"/project/ltfll/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/ltfll/","section":"project","summary":"LTfLL created next-generation educational services for learners and tutors, making extensive use of Language Technologies. The project created next-generation support and advice services to enhance individual and collaborative construction of knowledge in educational and organisational settings.","tags":["LTfLL"],"title":"LTfLL","type":"project"},{"authors":["Damien Dupré","Daniel Akpan","Elena Elias","Jean-Michel Adam","Brigite Meillon","Nicolas Bonnefond","Michel Dubois","Anna Tcherkassof"],"categories":null,"content":"","date":1446336000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1446336000,"objectID":"f0684dc6daaf4418b49af034e176b749","permalink":"/publication/2015-oudjat-ijhcs/","publishdate":"2015-11-01T00:00:00Z","relpermalink":"/publication/2015-oudjat-ijhcs/","section":"publication","summary":"This paper describes Oudjat, a new software for the manual annotation of stimuli involved in facial expressions of emotion (FEE) recognition experiments. Taking into account advantages and weaknesses of existing software and keeping in mind the different specifications needed for annotation experiments, Oudjat provides a tradeoff between existing tools. For investigators, it is an easy-to-configure interface to set up relevant behaviors to be annotated. For annotators, it is an easy-to-use interface. This tool can perform complex annotations procedures with multiple responses panels such as buttons, scales as Likert scales, and free labeling. Oudjat also allows to chain response panels or to conduct sequence marking annotations (i.e. two-steps temporal annotation). As it can be configured in any language, Oudjat is particularly suited for intercultural experiments. Four annotation procedures are presented to illustrate Oudjat possibilities with FEE annotation. Oudjat is an open source software available to the scientific community and can be obtained on request.","tags":null,"title":"Oudjat, a configurable and usable annotation tool for the study of emotional stimuli","type":"publication"},{"authors":["Damien Dupré","Michel Dubois","Anna Tcherkassof","Pascal Pizelle"],"categories":null,"content":"","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"059c9c31e357ea6ed5170847ab6ab49f","permalink":"/publication/2015-acceptabilite-innovatio/","publishdate":"2015-09-01T00:00:00Z","relpermalink":"/publication/2015-acceptabilite-innovatio/","section":"publication","summary":"Anticipating the success of a product is a key issue for manufacturers, particularly in the case of an innovative product. To reduce the risk of being rejected by its target users, the field of psychology has examined the determinants of the emotional user experience generated by a product. The emotion felt by the user is indeed a key factor that will influence the use of a product. This paper presents the different methods for measuring emotions. A literature review will compare the studies measuring the emotions of potential product users, the type of measures they use and their main results. This literature review reveals that despite the importance of measuring the emotions of users to predict the success of products, few of them are performed on real products on the one hand and with a hypothetical-deductive approach on the other. Although the factor structure of emotional user experience is not yet explored, this framework is relevant for understanding the role of users’ emotions in their adoption of innovative products.","tags":null,"title":"Cadres et méthodes d’analyse des émotions suscitées par des produits innovants : Une revue bibliographique","type":"publication"},{"authors":["Anna Tcherkassof","Damien Dupré","Brigite Meillon","Nadine Mandran","Michel Dubois","Jean-Michel Adam"],"categories":null,"content":"","date":1383264000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1383264000,"objectID":"5fe94f371cc15a1ea486a19f9c576749","permalink":"/publication/2013-dynemo-ijma/","publishdate":"2013-11-01T00:00:00Z","relpermalink":"/publication/2013-dynemo-ijma/","section":"publication","summary":"DynEmo is a database available to the scientific community (https://dynemo.upmf-grenoble.fr/). It contains dynamic and natural emotional facial expressions (EFEs) displaying subjective affective states rated by both the expresser and observers. Methodological and contextual information is provided for each expression. This multimodal corpus meets psychological, ethical, and technical criteria. It is quite large, containing two sets of 233 and 125 recordings of EFE of ordinary Caucasian people (ages 25 to 65, 182 females and 176 males) filmed in natural but standardized conditions. In the Set 1, EFE recordings are associated with the affective state of the expresser (self-reported after the emotion inducing task, using dimensional, action readiness, and emotional labels items). In the Set 2, EFE recordings are both associated with the affective state of the expresser and with the time line (continuous annotations) of observers' ratings of the emotions displayed throughout the recording. The time line allows any researcher interested in analysing non-verbal human behavior to segment the expressions into emotions.","tags":null,"title":"DynEmo: A video database of natural facial expressions of emotions","type":"publication"},{"authors":["Michel Dubois","Damien Dupré","Jean-Michel Adam","Anna Tcherkassof","Nadine Mandran","Brigite Meillon"],"categories":null,"content":"","date":1362096000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1362096000,"objectID":"79e32558600c5d7635fb96d24cd7a99a","permalink":"/publication/2013-interface-jmui/","publishdate":"2013-03-01T00:00:00Z","relpermalink":"/publication/2013-interface-jmui/","section":"publication","summary":"The use of facial interfaces in distant communications highlights the relevance of emotional recognition. However researches on emotional facial expression (EFE) recognition are mainly based on static and posed stimuli and their results are not much transferable to daily interactions. The purpose of the present study is to compare emotional recognition of authentic EFEs with 11 different interface designs. A widget allowing participants both to recognize an emotion and to assess it on-line was used. Divided-face and compound-face interfaces are compared with a common full frontal interface. Analytic and descriptive on-line results reveal that some interfaces facilitate emotional recognition whereas others would decrease it. This study suggests that relevant interfaces could improve emotional recognition and thus facilitate distant communications.","tags":null,"title":"The influence of facial designs interfaces on dynamic emotional recognition","type":"publication"},{"authors":["Damien Dupré","Mathieu Loiseau","Hamad Salem","Philipe Dessus","Stephan Simonian"],"categories":null,"content":"","date":1351728000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1351728000,"objectID":"c78336291ffe032fef2b23895aff8a3b","permalink":"/publication/2012-critere-re/","publishdate":"2012-11-01T00:00:00Z","relpermalink":"/publication/2012-critere-re/","section":"publication","summary":"","tags":null,"title":"Quelques critères d’utilisation d’un outil d’évaluation automatique de synthèses de cours à distance","type":"publication"},{"authors":["Philipe Dessus","S. Trausan-Matu","F. Wild","Damien Dupré","Mathieu Loiseau","T. Rebedea","V. Zampa"],"categories":null,"content":"","date":1320105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1320105600,"objectID":"cf72556bf7b02744c193325dd5cae0fe","permalink":"/publication/2011-environement-ds/","publishdate":"2011-11-01T00:00:00Z","relpermalink":"/publication/2011-environement-ds/","section":"publication","summary":"","tags":null,"title":"Un environnement personnel d'apprentissage évaluant des distances épistémiques et dialogiques","type":"publication"}]
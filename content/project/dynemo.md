+++
# Date this page was created.
date = "2016-04-27"

# Project title.
title = "DynEmo"

# Project summary to display on homepage.
summary = "DynEmo is a database available to the scientific community. It contains 358 dynamic and natural emotional facial expressions (EFEs) displaying subjective affective states rated by both the expresser and observers. Methodological and contextual information is provided for each expression. This multimodal corpus meets psychological, ethical, and technical criteria."

# Optional image to display on homepage (relative to `static/img/` folder).
image_preview = "dynemo-database-timeline.png"

# Tags: can be used for filtering projects.
# Example: `tags = ["machine-learning", "deep-learning"]`
tags = ["dynemo"]

# Optional external URL for project (replaces project detail page).
# external_link = "https://dynemo.univ-grenoble-alpes.fr/"
external_link = ""

# Does the project detail page use math formatting?
math = false

# Optional featured image (relative to `static/img/` folder).
[header]
image = "dynemo-database-timeline.png"
caption = "Disgust elicitation and recognition time-series"

+++

DynEmo is a database available to the scientific community (https://dynemo.univ-grenoble-alpes.fr/). It contains dynamic and natural emotional facial expressions (EFEs) displaying subjective affective states rated by both the expresser and observers. Methodological and contextual information is provided for each expression. This multimodal corpus meets psychological, ethical, and technical criteria. It is quite large, containing two sets of 233 and 125 recordings of EFE of ordinary Caucasian people (ages 25 to 65, 182 females and 176 males) filmed in natural but standardized conditions. In the Set 1, EFE recordings are associated with the affective state of the expresser (self-reported after the emotion inducing task, using dimensional, action readiness, and emotional labels items). In the Set 2, EFE recordings are both associated with the affective state of the expresser and with the time line (continuous annotations) of observersâ€™ ratings of the emotions displayed throughout the recording. The time line allows any researcher interested in analysing non-verbal human behavior to segment the expressions into small emotion excerpts.
